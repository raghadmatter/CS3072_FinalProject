---
title: "FinalProject"
output: html_document

---
params: 
    set_title: "CS3072_FinalProject"
---

---
title: `r params$set_title`
---
```

---
title: "Data Wrangling"
author: "Fatmah Alsalem, Joud Bawazir, Jana Nassir, Manal Asrar and Raghd Matar"
date: "11/20/2021"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
install.packages("usmap")
```


```{r}
library("tidyverse")
library(readr)
library(usmap)
library(ggplot2)
library(sf)
```

```{r}
income <- read_csv("C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/income.csv")
crime <- read_csv("C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/crime.csv")
edu_attainment <- read_csv("C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/edu_attainment.csv")
education_finance <- read_csv("C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/education_finance.csv")
unemployment <- read_csv("C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/unemployment.csv")
```

```{r}
income <- filter(income, !is.na(State))
```
Cleaning the data, getting rid of unwanted rows.

```{r}
crime <- mutate (crime, total_crime = violent_crime + property_crime)
crime <- subset (crime, select = -c(rape_revised, caveats))
crime <- rename(crime, state = state_name)
crime$state[is.na(crime$state)] <- "United States"
crime$state_abbr[is.na(crime$state_abbr)] <- "USA"
```

```{r}
crime_usa <- filter(crime, state == "United States")
```


```{r}
edu_attainment[edu_attainment == "United States (with PR)"] <- "United States"
edu_attainment<-subset(edu_attainment, state!="Puerto Rico")
```

Renaming data to make it compatible with other sets. Removed Puerto Rico since it doesn't exist in any other data sets.

```{r}
yearly_income <- gather(income, year, income, 2:38) 
yearly_income <- rename(yearly_income, state = State)
yearly_income$year <- as.numeric(yearly_income$year)
```

```{r cars}
yearly_unemployment <- gather(unemployment, year, unemployment, 2:40)
yearly_unemployment <- filter(yearly_unemployment, year>=1984)
yearly_unemployment$year <- as.numeric(yearly_unemployment$year)
```

```{r}
crime_usa <- full_join (crime_usa, yearly_income, by = c("state", "year"))
crime_usa <- full_join (crime_usa, yearly_unemployment, by = c("state", "year"))
crime_usa <- full_join (crime_usa, edu_attainment, by = c("state", "year"))
crime_usa <- filter(crime_usa, !is.na(population))
```

Making the yearly income and unemployment from wide to long such that the data becomes attachable to the main "crimes" table we created. 
```{r}
crime <- subset(crime, state != "United States")
yearly_income <- subset(yearly_income, state != "United States")
yearly_unemployment <- subset(yearly_unemployment, state != "United States")
```

```{r}
crimes <- filter(crime, year>=1984)
```


```{r}
crime_dataset <- full_join (crimes, yearly_income, by = c("state", "year"))
crime_dataset <- full_join (crime_dataset, yearly_unemployment, by = c("state", "year"))
crime_dataset <- filter(crime_dataset, year >= 1984, year<=2019)
```

This data set includes all the crime data from 1984 to 2019 including the income and unemployment rates.

```{r}
crime_dataset_edu <- crime_dataset
crime_dataset_edu <- full_join (crime_dataset_edu, edu_attainment, by = c("state", "year"))
crime_dataset_edu <- filter(crime_dataset_edu, year >= 2008, year <2020)
```

This data set is the same as crime data set but includes the educational attainment of people aged 25-64. The rate represents the number of adults in this age range who have studied after high school. It was made into a separate table because the data about the education is only from 2008.

```{r}
edu_finance <- education_finance
edu_finance <- rename(edu_finance, year = YEAR, state = STATE)
edu_finance <- full_join(edu_finance, crime_dataset_edu, by = c("state", "year"))
edu_finance <- filter(edu_finance, year >= 2008, year < 2017)
edu_finance <-subset(edu_finance, state!="United States")
```


This table is similar to the one before except that it include the amount of money that the government spends on financing for schools. It was made into another data set because it is only up to 2017. 






```{r}
write.table (crime_dataset, file = "C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/MODIFIED/unemployment.csv", row.names = F, sep = ",")

write.table (crime_dataset_edu, file = "C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/MODIFIED/crime_dataset_edu.csv", row.names = F, sep = ",")

write.table (crimes, file = "C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/MODIFIED/crimes.csv", row.names = F, sep = ",")

write.table (yearly_income, file = "C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/MODIFIED/yearly_income.csv", row.names = F, sep = ",")

write.table (yearly_unemployment, file = "C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/MODIFIED/yearly_unemployment.csv", row.names = F, sep = ",")

write.table (edu_finance, file = "C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/MODIFIED/edu_finance.csv", row.names = F, sep = ",")

write.table (crime_usa, file = "C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/MODIFIED/crime_usa.csv", row.names = F, sep = ",")
```

To download the tables. 

```{r}
av_crime <- crimes %>% group_by(state, state_abbr) %>% summarize(av_population = mean(population), crime_num = mean(total_crime), crime_rate = (crime_num/av_population)*100, pcrime = mean(property_crime), pcrime_rate = (pcrime/ av_population)*100, vcrime = mean(violent_crime), vcrime_rate = (vcrime/av_population)*100)

```
```{r}
statesmap<-st_read("C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/cb_2018_us_state_5m.shp")

```

```{r}
statesmap <- rename(statesmap, state_abbr = STUSPS)
```

```{r}
crime_map <- full_join (statesmap, av_crime, by = c("state_abbr"))
```

```{r}
ggplot(data = crime_map, aes(geometry = geometry))+
  geom_sf(aes(fill="state_abbr")) +
  scale_fill_manual(values = c("#DE0100", "#0015BC")) +
  labs(
    title = "crime rates from 1984 to 2019"
  ) +
  theme_bw()

```
av_crime <- crimes %>% group_by(state, state_abbr) %>% summarize(av_population = mean(population), crime_num = mean(total_crime), crime_rate = (crime_num/av_population)*100, pcrime = mean(property_crime), pcrime_rate = (pcrime/ av_population)*100, vcrime = mean(violent_crime), vcrime_rate = (vcrime/av_population)*100)

```


Does higher average income  mean less crime or the opposite. (explore)

```{r}

av_income <- edu_finance %>% group_by(state, state_abbr) %>% summarize(av_population = mean(population),   crime_num =mean(total_crime),crime_rate =(crime_num/av_population)*100, vincome= mean(income), vcrime_rate = (vincome/av_population)*100)

```





```{r}

av_unemployement <- edu_finance %>% group_by(state, state_abbr, year, unemployment) %>% summarize(av_population = mean(population),   crime_num =mean(total_crime),crime_rate =(crime_num/av_population)*100)

```


```{r}
ggplot(av_income,mapping=aes(x=crime_rate  , y= vincome, color=state_abbr))+geom_point( ) + 
  labs(title = "Does higher average income mean less crime or the opposite?",x = "INCOME", y = "Crime Rate")+theme_bw()

```


```{r}

crime_USA_filtered <- crime_usa %>% group_by(state, state_abbr, year, income, unemployment)%>% filter ( year >= 2007)%>% summarize(  crime_num =mean(total_crime),crime_rate =(crime_num/population)*100)


ggplot(crime_USA_filtered,mapping=aes(x= income, y= crime_rate))+geom_line() +  labs(title = "Does higher average income mean less crime or the opposite?",x = "Income", y = "Crime Rate")+theme_bw()
```





```{r}


ggplot(crime_USA_filtered,mapping=aes(x=year , y=crime_rate ))+geom_step() +  labs(title = "Does lower unemployement rate mean less crime?",x = "year", y = "crime rate")+theme_bw()


ggplot(crime_USA_filtered,mapping=aes(x=year , y=unemployment ))+geom_step() +  labs(title = "Does lower unemployement rate mean less crime?",x = "year", y = "Unemployment")+theme_dark()



ggplot(crime_USA_filtered,mapping=aes(x=year  , y= crime_rate, color=unemployment))+geom_point( ) + 
  labs(title = "Unemployment vs crime rate",x = "year", y = "Crime Rate")+theme_bw()




```









```{r}




unemployment_model <- lm(crime_rate ~ unemployment, data = av_unemployement)
tidy(unemployment_model)





```

crimeRate= 2.3+0.13UnemployementPercentile.

```{r}


```

```{r}


unemployment_model %>% 
  augment() %>% 
  ggplot(mapping = aes(x = unemployment, y = crime_rate)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_point(mapping = aes(y = .fitted)) +
  geom_segment(mapping = aes(xend = unemployment, yend = .fitted), 
               alpha = 0.4, color="red") +
  ylim(0, 5) +
  labs(x = "unemployment", y = "crime_rate") +
  theme_bw() + labs(title = "Linear Regression between Unemployement and Crime Rates",x = "Unemployement", y = "Crime Rates")+theme_bw()







```



Does spending more money on the education system lower crime rate? Total Expenditure Vs. Total Revenue Vs Crime Rates (explore)

```{r}











```





```{r}
edu_finance3 <- edu_finance %>% group_by(state,state_abbr)%>%summarize(av_population = mean(population),crime_num =mean(total_crime),crime_rate =(crime_num/av_population)*100, av_total_rev= mean(TOTAL_REVENUE)/1000000, av_total_exp = mean(TOTAL_EXPENDITURE)/1000000, av_total_enroll = mean(ENROLL)/100000)%>%
  arrange(desc(crime_rate))

edu_finance4<-edu_finance3[c(1,7, 14, 21, 28, 35, 42, 49),]
  
  
```

```{r}
edu_finance4<-filter(edu_finance2, state %in% c("District of Columbia", "Washington", "Oklahoma", "Colorado", "Virginia", "New York")) %>% group_by(year)
  
```

```{r}
edu_finance4 <- mutate(edu_finance4, exp = vTOTAL_EXPENDITURE/1000000)
```

```{r}
    library(lubridate)
    library(tidyverse)

  ggplot(edu_finance4, aes(x=year ,y= crime_rate, size=exp)) +
  geom_point() + scale_fill_gradient(low = "#ffff00", high = "#ff00ff") + labs(title = "Does spending more money in the education system lower Crime Rates?",x = "Year", y = "Crime rate")+theme_bw() 
  
```


```{r}
install.packages('caret', dependencies = TRUE)
```

```{r}
install.packages('DEoptimR') 
install.packages("caret", dependencies = TRUE)
```
```{r}
install.packages("caret",dep = TRUE)
install.packages("ggplot2")
install.packages("lattice")
install.packages("lava")
install.packages("purrr")

library(ggplot2)
library(lattice)
library(lava)
library(purrr)
library(caret)
```




```{r}
library(caret)
```


```{r}
pred_crime <- read.csv('C:/Users/manal/OneDrive/Desktop/CS3072_FinalProject/Datasets/datasets/MODIFIED/crime_dataset.csv')
```

```{r}
str(pred_crime)
head(pred_crime[, 1:10])
pred_crime2<-pred_crime[1:300,]
```
```{r}
#install.packages("dplyr") 
library(dplyr)
```


```{r}
pred_crime <- filter(pred_crime, !is.na(violent_crime), !is.na(income), !is.na(unemployment))
```


```{r}
# Create the training and test datasets
set.seed(100)
```


```{r}
# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(y=pred_crime$total_crime, p=0.8, list=FALSE)

# Step 2: Create the training  dataset
trainData <- pred_crime[trainRowNumbers,]
trainData$income = as.numeric(gsub(",", "", trainData$income))
trainData$income = as.numeric(trainData$income)
# Step 3: Create the test dataset

testData <- pred_crime[-trainRowNumbers,]
testData$income = as.numeric(gsub(",", "", testData$income))
testData$income = as.numeric(testData$income)
# Store X and Y for later use.
x = trainData[2:18,]
y = trainData$total_crime
```

```{r}
install.packages("skimr") 
library(skimr)
```
```{r}
skimmed <- skim_to_wide(trainData)
skimmed[, c(1:5, 9:11, 13, 15:16)]
```


```{r}
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(trainData, method='knnImpute')
preProcess_missingdata_model

# Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnImpute
trainData <- predict(preProcess_missingdata_model, newdata = trainData)
anyNA(trainData)
```


```{r}
#dummies_model <- dummyVars(total_crime ~ ., data=trainData)

#trainData_mat <- predict(dummies_model, newdata = trainData)

#trainData <- data.frame(trainData_mat)

#str(trainData)

```

```{r}
modelnames <- paste(names(getModelInfo()), collapse=',  ')
modelnames

```

```{r}
modelLookup("nodeHarvest")

```

```{r}
set.seed(100)
options(warn=-1)

subsets <- c(1:13, 15:16)

ctrl <- rfeControl(functions = rfFuncs,
                   method = "repeatedcv",
                   repeats = 5,
                   verbose = FALSE)

lmProfile <- rfe(x=trainData[subsets], y=trainData$total_crime,
                 sizes = subsets,
                 rfeControl = ctrl)

lmProfile
```
```{r}
is.numeric(testData$income)
```


```{r}
# Step 1: Impute missing values 
testData2 <- predict(preProcess_missingdata_model, testData)  

# Step 3: Transform the features to range between 0 and 1
#testData3 <- predict(preProcess_range_model, testData2)

# View
head(testData2[, 1:10])
is.numeric(testData2$income)

```
```{r}
trainData <- filter(trainData, !is.na(violent_crime), !is.na(income), !is.na(unemployment))
```


```{r}
#fit control wasnt included
model_rf = train(total_crime ~ ., data=trainData, method='rf')
fitted <- predict(model_rf)
model_rf

```


```{r}
# Predict on testData
predicted <- predict(model_rf, testData2)
head(predicted)
```



```{r}
set.seed(100)

# Train the model using SVM
model_svmRadial = train(total_crime ~ ., data=trainData, method='svmRadial', tuneLength=15)
model_svmRadial
```
```{r}
#predict
testData2 <- filter(testData2, !is.na(violent_crime), !is.na(income), !is.na(unemployment))
```

```{r}
# Predict on testData
predicted <- predict(model_svmRadial, testData2)
head(predicted)
```



```{r}
set.seed(100)

# Train the model using logreg wrong
model_logreg = train(total_crime ~ ., data=trainData, method='logreg', tuneLength=2)
model_logreg
```

```{r}
set.seed(100)

# Train the model using nnet
model_nnet = train(total_crime ~ ., data=trainData, method='nnet', tuneLength=2)
model_nnet
```

```{r}
set.seed(100)

# Train the model using 
model_ctree = train(total_crime ~ ., data=trainData, method='ctree', tuneLength=2)
model_ctree
```


```{r}
set.seed(100)

# Train the model using xgbLinear
model_xgbLinear = train(total_crime ~ ., data=trainData, method='xgbLinear', tuneLength=2)
model_xgbLinear
```

```{r}
set.seed(100)

# Train the model using nodeHarvest
model_nodeHarvest = train(total_crime ~ ., data=trainData, method='nodeHarvest', tuneLength=2)
model_nodeHarvest
```

```{r}
# Compare model performances using resample()
models_compare <- resamples(list(svmRadial=model_svmRadial, NNET=model_nnet, CTREE=model_ctree, XGBLINEAR=model_xgbLinear, NODEHARVEST=model_nodeHarvest))
```

```{r}
# Summary of the models performances
summary(models_compare)

```

